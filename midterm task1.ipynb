{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as T\n",
    "\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "NUM_TRAIN = 49000\n",
    "\n",
    "transform = T.Compose([\n",
    "                T.ToTensor(),\n",
    "                T.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "            ])\n",
    "\n",
    "cifar10_train = dset.CIFAR10('./datasets', train=True, download=True,\n",
    "                             transform=transform)\n",
    "loader_train = DataLoader(cifar10_train, batch_size=64, \n",
    "                          sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN)))\n",
    "\n",
    "cifar10_val = dset.CIFAR10('./datasets', train=True, download=True,\n",
    "                           transform=transform)\n",
    "loader_val = DataLoader(cifar10_val, batch_size=64, \n",
    "                        sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN, 50000)))\n",
    "\n",
    "cifar10_test = dset.CIFAR10('./datasets', train=False, download=True, \n",
    "                            transform=transform)\n",
    "loader_test = DataLoader(cifar10_test, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cuda\n"
     ]
    }
   ],
   "source": [
    "USE_GPU = True\n",
    "\n",
    "dtype = torch.float32 \n",
    "\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "print_every = 100\n",
    "\n",
    "print('using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return flatten(x)\n",
    "    \n",
    "def train(model, optimizer, epochs=1):\n",
    "\n",
    "    model = model.to(device=device)\n",
    "    Loss_list = []\n",
    "    Accuracy_list = []\n",
    "    for e in range(epochs):\n",
    "        for t, (x, y) in enumerate(loader_train):\n",
    "            model.train()  \n",
    "            x = x.to(device=device, dtype=dtype)  \n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "\n",
    "            scores = model(x)\n",
    "            loss = F.cross_entropy(scores, y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if t % print_every == 0:\n",
    "                print('Iteration %d, loss = %.4f' % (t, loss.item()))\n",
    "                acc,num_correct,num_samples = check_accuracy(loader_val, model)\n",
    "                print()\n",
    "        Loss_list.append(loss.item() ) \n",
    "        Accuracy_list.append(100 * acc)\n",
    "def check_accuracy(loader, model):\n",
    "    if loader.dataset.train:\n",
    "        print('Checking accuracy on validation set')\n",
    "    else:\n",
    "        print('Checking accuracy on test set')   \n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval() \n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device=device, dtype=dtype) \n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "            scores = model(x)\n",
    "            _, preds = scores.max(1)\n",
    "            num_correct += (preds == y).sum()\n",
    "            num_samples += preds.size(0)\n",
    "        acc = float(num_correct) / num_samples\n",
    "        print('Got %d / %d correct (%.2f%%)' % (num_correct, num_samples, 100 * acc))  \n",
    "        return (acc,num_correct,num_samples)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, loss = 2.3043\n",
      "Checking accuracy on validation set\n",
      "Got 113 / 1000 correct (11.30%)\n",
      "\n",
      "Iteration 100, loss = 2.1028\n",
      "Checking accuracy on validation set\n",
      "Got 238 / 1000 correct (23.80%)\n",
      "\n",
      "Iteration 200, loss = 2.0637\n",
      "Checking accuracy on validation set\n",
      "Got 231 / 1000 correct (23.10%)\n",
      "\n",
      "Iteration 300, loss = 2.0389\n",
      "Checking accuracy on validation set\n",
      "Got 239 / 1000 correct (23.90%)\n",
      "\n",
      "Iteration 400, loss = 2.0790\n",
      "Checking accuracy on validation set\n",
      "Got 287 / 1000 correct (28.70%)\n",
      "\n",
      "Iteration 500, loss = 1.9954\n",
      "Checking accuracy on validation set\n",
      "Got 290 / 1000 correct (29.00%)\n",
      "\n",
      "Iteration 600, loss = 1.7243\n",
      "Checking accuracy on validation set\n",
      "Got 302 / 1000 correct (30.20%)\n",
      "\n",
      "Iteration 700, loss = 1.7222\n",
      "Checking accuracy on validation set\n",
      "Got 356 / 1000 correct (35.60%)\n",
      "\n",
      "Iteration 0, loss = 1.7803\n",
      "Checking accuracy on validation set\n",
      "Got 339 / 1000 correct (33.90%)\n",
      "\n",
      "Iteration 100, loss = 1.4311\n",
      "Checking accuracy on validation set\n",
      "Got 357 / 1000 correct (35.70%)\n",
      "\n",
      "Iteration 200, loss = 1.6656\n",
      "Checking accuracy on validation set\n",
      "Got 430 / 1000 correct (43.00%)\n",
      "\n",
      "Iteration 300, loss = 1.6030\n",
      "Checking accuracy on validation set\n",
      "Got 462 / 1000 correct (46.20%)\n",
      "\n",
      "Iteration 400, loss = 1.3621\n",
      "Checking accuracy on validation set\n",
      "Got 465 / 1000 correct (46.50%)\n",
      "\n",
      "Iteration 500, loss = 1.5239\n",
      "Checking accuracy on validation set\n",
      "Got 472 / 1000 correct (47.20%)\n",
      "\n",
      "Iteration 600, loss = 1.6303\n",
      "Checking accuracy on validation set\n",
      "Got 475 / 1000 correct (47.50%)\n",
      "\n",
      "Iteration 700, loss = 1.6472\n",
      "Checking accuracy on validation set\n",
      "Got 478 / 1000 correct (47.80%)\n",
      "\n",
      "Iteration 0, loss = 1.1838\n",
      "Checking accuracy on validation set\n",
      "Got 520 / 1000 correct (52.00%)\n",
      "\n",
      "Iteration 100, loss = 1.0324\n",
      "Checking accuracy on validation set\n",
      "Got 564 / 1000 correct (56.40%)\n",
      "\n",
      "Iteration 200, loss = 1.3068\n",
      "Checking accuracy on validation set\n",
      "Got 569 / 1000 correct (56.90%)\n",
      "\n",
      "Iteration 300, loss = 1.3003\n",
      "Checking accuracy on validation set\n",
      "Got 575 / 1000 correct (57.50%)\n",
      "\n",
      "Iteration 400, loss = 1.2870\n",
      "Checking accuracy on validation set\n",
      "Got 563 / 1000 correct (56.30%)\n",
      "\n",
      "Iteration 500, loss = 1.5321\n",
      "Checking accuracy on validation set\n",
      "Got 565 / 1000 correct (56.50%)\n",
      "\n",
      "Iteration 600, loss = 1.1126\n",
      "Checking accuracy on validation set\n",
      "Got 635 / 1000 correct (63.50%)\n",
      "\n",
      "Iteration 700, loss = 0.9475\n",
      "Checking accuracy on validation set\n",
      "Got 637 / 1000 correct (63.70%)\n",
      "\n",
      "Iteration 0, loss = 1.1631\n",
      "Checking accuracy on validation set\n",
      "Got 636 / 1000 correct (63.60%)\n",
      "\n",
      "Iteration 100, loss = 1.0092\n",
      "Checking accuracy on validation set\n",
      "Got 631 / 1000 correct (63.10%)\n",
      "\n",
      "Iteration 200, loss = 0.9104\n",
      "Checking accuracy on validation set\n",
      "Got 657 / 1000 correct (65.70%)\n",
      "\n",
      "Iteration 300, loss = 1.0096\n",
      "Checking accuracy on validation set\n",
      "Got 643 / 1000 correct (64.30%)\n",
      "\n",
      "Iteration 400, loss = 0.8762\n",
      "Checking accuracy on validation set\n",
      "Got 689 / 1000 correct (68.90%)\n",
      "\n",
      "Iteration 500, loss = 1.0104\n",
      "Checking accuracy on validation set\n",
      "Got 697 / 1000 correct (69.70%)\n",
      "\n",
      "Iteration 600, loss = 0.9913\n",
      "Checking accuracy on validation set\n",
      "Got 696 / 1000 correct (69.60%)\n",
      "\n",
      "Iteration 700, loss = 0.7060\n",
      "Checking accuracy on validation set\n",
      "Got 679 / 1000 correct (67.90%)\n",
      "\n",
      "Iteration 0, loss = 0.7505\n",
      "Checking accuracy on validation set\n",
      "Got 705 / 1000 correct (70.50%)\n",
      "\n",
      "Iteration 100, loss = 1.0494\n",
      "Checking accuracy on validation set\n",
      "Got 730 / 1000 correct (73.00%)\n",
      "\n",
      "Iteration 200, loss = 0.7869\n",
      "Checking accuracy on validation set\n",
      "Got 700 / 1000 correct (70.00%)\n",
      "\n",
      "Iteration 300, loss = 0.6328\n",
      "Checking accuracy on validation set\n",
      "Got 694 / 1000 correct (69.40%)\n",
      "\n",
      "Iteration 400, loss = 0.7578\n",
      "Checking accuracy on validation set\n",
      "Got 702 / 1000 correct (70.20%)\n",
      "\n",
      "Iteration 500, loss = 0.6369\n",
      "Checking accuracy on validation set\n",
      "Got 737 / 1000 correct (73.70%)\n",
      "\n",
      "Iteration 600, loss = 0.8731\n",
      "Checking accuracy on validation set\n",
      "Got 712 / 1000 correct (71.20%)\n",
      "\n",
      "Iteration 700, loss = 0.8106\n",
      "Checking accuracy on validation set\n",
      "Got 739 / 1000 correct (73.90%)\n",
      "\n",
      "Iteration 0, loss = 0.5918\n",
      "Checking accuracy on validation set\n",
      "Got 712 / 1000 correct (71.20%)\n",
      "\n",
      "Iteration 100, loss = 0.6688\n",
      "Checking accuracy on validation set\n",
      "Got 700 / 1000 correct (70.00%)\n",
      "\n",
      "Iteration 200, loss = 0.7996\n",
      "Checking accuracy on validation set\n",
      "Got 726 / 1000 correct (72.60%)\n",
      "\n",
      "Iteration 300, loss = 0.8218\n",
      "Checking accuracy on validation set\n",
      "Got 753 / 1000 correct (75.30%)\n",
      "\n",
      "Iteration 400, loss = 0.6053\n",
      "Checking accuracy on validation set\n",
      "Got 717 / 1000 correct (71.70%)\n",
      "\n",
      "Iteration 500, loss = 0.8646\n",
      "Checking accuracy on validation set\n",
      "Got 750 / 1000 correct (75.00%)\n",
      "\n",
      "Iteration 600, loss = 0.6245\n",
      "Checking accuracy on validation set\n",
      "Got 747 / 1000 correct (74.70%)\n",
      "\n",
      "Iteration 700, loss = 0.5714\n",
      "Checking accuracy on validation set\n",
      "Got 765 / 1000 correct (76.50%)\n",
      "\n",
      "Iteration 0, loss = 0.6217\n",
      "Checking accuracy on validation set\n",
      "Got 755 / 1000 correct (75.50%)\n",
      "\n",
      "Iteration 100, loss = 0.4860\n",
      "Checking accuracy on validation set\n",
      "Got 759 / 1000 correct (75.90%)\n",
      "\n",
      "Iteration 200, loss = 0.9138\n",
      "Checking accuracy on validation set\n",
      "Got 765 / 1000 correct (76.50%)\n",
      "\n",
      "Iteration 300, loss = 0.3768\n",
      "Checking accuracy on validation set\n",
      "Got 768 / 1000 correct (76.80%)\n",
      "\n",
      "Iteration 400, loss = 0.6575\n",
      "Checking accuracy on validation set\n",
      "Got 759 / 1000 correct (75.90%)\n",
      "\n",
      "Iteration 500, loss = 0.6102\n",
      "Checking accuracy on validation set\n",
      "Got 783 / 1000 correct (78.30%)\n",
      "\n",
      "Iteration 600, loss = 0.4888\n",
      "Checking accuracy on validation set\n",
      "Got 781 / 1000 correct (78.10%)\n",
      "\n",
      "Iteration 700, loss = 0.5936\n",
      "Checking accuracy on validation set\n",
      "Got 762 / 1000 correct (76.20%)\n",
      "\n",
      "Iteration 0, loss = 0.5423\n",
      "Checking accuracy on validation set\n",
      "Got 769 / 1000 correct (76.90%)\n",
      "\n",
      "Iteration 100, loss = 0.6423\n",
      "Checking accuracy on validation set\n",
      "Got 771 / 1000 correct (77.10%)\n",
      "\n",
      "Iteration 200, loss = 0.3462\n",
      "Checking accuracy on validation set\n",
      "Got 748 / 1000 correct (74.80%)\n",
      "\n",
      "Iteration 300, loss = 0.6782\n",
      "Checking accuracy on validation set\n",
      "Got 764 / 1000 correct (76.40%)\n",
      "\n",
      "Iteration 400, loss = 0.6998\n",
      "Checking accuracy on validation set\n",
      "Got 779 / 1000 correct (77.90%)\n",
      "\n",
      "Iteration 500, loss = 0.6347\n",
      "Checking accuracy on validation set\n",
      "Got 778 / 1000 correct (77.80%)\n",
      "\n",
      "Iteration 600, loss = 0.6677\n",
      "Checking accuracy on validation set\n",
      "Got 780 / 1000 correct (78.00%)\n",
      "\n",
      "Iteration 700, loss = 0.5122\n",
      "Checking accuracy on validation set\n",
      "Got 771 / 1000 correct (77.10%)\n",
      "\n",
      "Iteration 0, loss = 0.4772\n",
      "Checking accuracy on validation set\n",
      "Got 778 / 1000 correct (77.80%)\n",
      "\n",
      "Iteration 100, loss = 0.7033\n",
      "Checking accuracy on validation set\n",
      "Got 781 / 1000 correct (78.10%)\n",
      "\n",
      "Iteration 200, loss = 0.5943\n",
      "Checking accuracy on validation set\n",
      "Got 783 / 1000 correct (78.30%)\n",
      "\n",
      "Iteration 300, loss = 0.5615\n",
      "Checking accuracy on validation set\n",
      "Got 783 / 1000 correct (78.30%)\n",
      "\n",
      "Iteration 400, loss = 0.6112\n",
      "Checking accuracy on validation set\n",
      "Got 782 / 1000 correct (78.20%)\n",
      "\n",
      "Iteration 500, loss = 0.4527\n",
      "Checking accuracy on validation set\n",
      "Got 798 / 1000 correct (79.80%)\n",
      "\n",
      "Iteration 600, loss = 0.4406\n",
      "Checking accuracy on validation set\n",
      "Got 769 / 1000 correct (76.90%)\n",
      "\n",
      "Iteration 700, loss = 0.4893\n",
      "Checking accuracy on validation set\n",
      "Got 785 / 1000 correct (78.50%)\n",
      "\n",
      "Iteration 0, loss = 0.5923\n",
      "Checking accuracy on validation set\n",
      "Got 762 / 1000 correct (76.20%)\n",
      "\n",
      "Iteration 100, loss = 0.4278\n",
      "Checking accuracy on validation set\n",
      "Got 799 / 1000 correct (79.90%)\n",
      "\n",
      "Iteration 200, loss = 0.6547\n",
      "Checking accuracy on validation set\n",
      "Got 799 / 1000 correct (79.90%)\n",
      "\n",
      "Iteration 300, loss = 0.4198\n",
      "Checking accuracy on validation set\n",
      "Got 780 / 1000 correct (78.00%)\n",
      "\n",
      "Iteration 400, loss = 0.5061\n",
      "Checking accuracy on validation set\n",
      "Got 797 / 1000 correct (79.70%)\n",
      "\n",
      "Iteration 500, loss = 0.5031\n",
      "Checking accuracy on validation set\n",
      "Got 798 / 1000 correct (79.80%)\n",
      "\n",
      "Iteration 600, loss = 0.6200\n",
      "Checking accuracy on validation set\n",
      "Got 768 / 1000 correct (76.80%)\n",
      "\n",
      "Iteration 700, loss = 0.4860\n",
      "Checking accuracy on validation set\n",
      "Got 777 / 1000 correct (77.70%)\n",
      "\n",
      "Iteration 0, loss = 0.3605\n",
      "Checking accuracy on validation set\n",
      "Got 781 / 1000 correct (78.10%)\n",
      "\n",
      "Iteration 100, loss = 0.3314\n",
      "Checking accuracy on validation set\n",
      "Got 792 / 1000 correct (79.20%)\n",
      "\n",
      "Iteration 200, loss = 0.4238\n",
      "Checking accuracy on validation set\n",
      "Got 793 / 1000 correct (79.30%)\n",
      "\n",
      "Iteration 300, loss = 0.3951\n",
      "Checking accuracy on validation set\n",
      "Got 811 / 1000 correct (81.10%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 400, loss = 0.5144\n",
      "Checking accuracy on validation set\n",
      "Got 796 / 1000 correct (79.60%)\n",
      "\n",
      "Iteration 500, loss = 0.2435\n",
      "Checking accuracy on validation set\n",
      "Got 786 / 1000 correct (78.60%)\n",
      "\n",
      "Iteration 600, loss = 0.6228\n",
      "Checking accuracy on validation set\n",
      "Got 789 / 1000 correct (78.90%)\n",
      "\n",
      "Iteration 700, loss = 0.4689\n",
      "Checking accuracy on validation set\n",
      "Got 786 / 1000 correct (78.60%)\n",
      "\n",
      "Iteration 0, loss = 0.4986\n",
      "Checking accuracy on validation set\n",
      "Got 772 / 1000 correct (77.20%)\n",
      "\n",
      "Iteration 100, loss = 0.6098\n",
      "Checking accuracy on validation set\n",
      "Got 792 / 1000 correct (79.20%)\n",
      "\n",
      "Iteration 200, loss = 0.3904\n",
      "Checking accuracy on validation set\n",
      "Got 787 / 1000 correct (78.70%)\n",
      "\n",
      "Iteration 300, loss = 0.4758\n",
      "Checking accuracy on validation set\n",
      "Got 803 / 1000 correct (80.30%)\n",
      "\n",
      "Iteration 400, loss = 0.4760\n",
      "Checking accuracy on validation set\n",
      "Got 772 / 1000 correct (77.20%)\n",
      "\n",
      "Iteration 500, loss = 0.2786\n",
      "Checking accuracy on validation set\n",
      "Got 797 / 1000 correct (79.70%)\n",
      "\n",
      "Iteration 600, loss = 0.3596\n",
      "Checking accuracy on validation set\n",
      "Got 794 / 1000 correct (79.40%)\n",
      "\n",
      "Iteration 700, loss = 0.4079\n",
      "Checking accuracy on validation set\n",
      "Got 816 / 1000 correct (81.60%)\n",
      "\n",
      "Iteration 0, loss = 0.4523\n",
      "Checking accuracy on validation set\n",
      "Got 804 / 1000 correct (80.40%)\n",
      "\n",
      "Iteration 100, loss = 0.5109\n",
      "Checking accuracy on validation set\n",
      "Got 786 / 1000 correct (78.60%)\n",
      "\n",
      "Iteration 200, loss = 0.4971\n",
      "Checking accuracy on validation set\n",
      "Got 786 / 1000 correct (78.60%)\n",
      "\n",
      "Iteration 300, loss = 0.3926\n",
      "Checking accuracy on validation set\n",
      "Got 803 / 1000 correct (80.30%)\n",
      "\n",
      "Iteration 400, loss = 0.3158\n",
      "Checking accuracy on validation set\n",
      "Got 791 / 1000 correct (79.10%)\n",
      "\n",
      "Iteration 500, loss = 0.5211\n",
      "Checking accuracy on validation set\n",
      "Got 804 / 1000 correct (80.40%)\n",
      "\n",
      "Iteration 600, loss = 0.4209\n",
      "Checking accuracy on validation set\n",
      "Got 808 / 1000 correct (80.80%)\n",
      "\n",
      "Iteration 700, loss = 0.5424\n",
      "Checking accuracy on validation set\n",
      "Got 804 / 1000 correct (80.40%)\n",
      "\n",
      "Iteration 0, loss = 0.5016\n",
      "Checking accuracy on validation set\n",
      "Got 801 / 1000 correct (80.10%)\n",
      "\n",
      "Iteration 100, loss = 0.3575\n",
      "Checking accuracy on validation set\n",
      "Got 818 / 1000 correct (81.80%)\n",
      "\n",
      "Iteration 200, loss = 0.3817\n",
      "Checking accuracy on validation set\n",
      "Got 819 / 1000 correct (81.90%)\n",
      "\n",
      "Iteration 300, loss = 0.3946\n",
      "Checking accuracy on validation set\n",
      "Got 806 / 1000 correct (80.60%)\n",
      "\n",
      "Iteration 400, loss = 0.3669\n",
      "Checking accuracy on validation set\n",
      "Got 801 / 1000 correct (80.10%)\n",
      "\n",
      "Iteration 500, loss = 0.3585\n",
      "Checking accuracy on validation set\n",
      "Got 803 / 1000 correct (80.30%)\n",
      "\n",
      "Iteration 600, loss = 0.3013\n",
      "Checking accuracy on validation set\n",
      "Got 795 / 1000 correct (79.50%)\n",
      "\n",
      "Iteration 700, loss = 0.2851\n",
      "Checking accuracy on validation set\n",
      "Got 797 / 1000 correct (79.70%)\n",
      "\n",
      "Iteration 0, loss = 0.4265\n",
      "Checking accuracy on validation set\n",
      "Got 825 / 1000 correct (82.50%)\n",
      "\n",
      "Iteration 100, loss = 0.2189\n",
      "Checking accuracy on validation set\n",
      "Got 803 / 1000 correct (80.30%)\n",
      "\n",
      "Iteration 200, loss = 0.3250\n",
      "Checking accuracy on validation set\n",
      "Got 812 / 1000 correct (81.20%)\n",
      "\n",
      "Iteration 300, loss = 0.4260\n",
      "Checking accuracy on validation set\n",
      "Got 793 / 1000 correct (79.30%)\n",
      "\n",
      "Iteration 400, loss = 0.2797\n",
      "Checking accuracy on validation set\n",
      "Got 811 / 1000 correct (81.10%)\n",
      "\n",
      "Iteration 500, loss = 0.3042\n",
      "Checking accuracy on validation set\n",
      "Got 813 / 1000 correct (81.30%)\n",
      "\n",
      "Iteration 600, loss = 0.3334\n",
      "Checking accuracy on validation set\n",
      "Got 802 / 1000 correct (80.20%)\n",
      "\n",
      "Iteration 700, loss = 0.3948\n",
      "Checking accuracy on validation set\n",
      "Got 801 / 1000 correct (80.10%)\n",
      "\n",
      "Iteration 0, loss = 0.2478\n",
      "Checking accuracy on validation set\n",
      "Got 793 / 1000 correct (79.30%)\n",
      "\n",
      "Iteration 100, loss = 0.2148\n",
      "Checking accuracy on validation set\n",
      "Got 813 / 1000 correct (81.30%)\n",
      "\n",
      "Iteration 200, loss = 0.4285\n",
      "Checking accuracy on validation set\n",
      "Got 813 / 1000 correct (81.30%)\n",
      "\n",
      "Iteration 300, loss = 0.3105\n",
      "Checking accuracy on validation set\n",
      "Got 808 / 1000 correct (80.80%)\n",
      "\n",
      "Iteration 400, loss = 0.3297\n",
      "Checking accuracy on validation set\n",
      "Got 803 / 1000 correct (80.30%)\n",
      "\n",
      "Iteration 500, loss = 0.2193\n",
      "Checking accuracy on validation set\n",
      "Got 822 / 1000 correct (82.20%)\n",
      "\n",
      "Iteration 600, loss = 0.3103\n",
      "Checking accuracy on validation set\n",
      "Got 802 / 1000 correct (80.20%)\n",
      "\n",
      "Iteration 700, loss = 0.3217\n",
      "Checking accuracy on validation set\n",
      "Got 812 / 1000 correct (81.20%)\n",
      "\n",
      "Iteration 0, loss = 0.5208\n",
      "Checking accuracy on validation set\n",
      "Got 785 / 1000 correct (78.50%)\n",
      "\n",
      "Iteration 100, loss = 0.2497\n",
      "Checking accuracy on validation set\n",
      "Got 821 / 1000 correct (82.10%)\n",
      "\n",
      "Iteration 200, loss = 0.2971\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90%)\n",
      "\n",
      "Iteration 300, loss = 0.3885\n",
      "Checking accuracy on validation set\n",
      "Got 810 / 1000 correct (81.00%)\n",
      "\n",
      "Iteration 400, loss = 0.2886\n",
      "Checking accuracy on validation set\n",
      "Got 806 / 1000 correct (80.60%)\n",
      "\n",
      "Iteration 500, loss = 0.2494\n",
      "Checking accuracy on validation set\n",
      "Got 808 / 1000 correct (80.80%)\n",
      "\n",
      "Iteration 600, loss = 0.4428\n",
      "Checking accuracy on validation set\n",
      "Got 814 / 1000 correct (81.40%)\n",
      "\n",
      "Iteration 700, loss = 0.2467\n",
      "Checking accuracy on validation set\n",
      "Got 806 / 1000 correct (80.60%)\n",
      "\n",
      "Iteration 0, loss = 0.4771\n",
      "Checking accuracy on validation set\n",
      "Got 811 / 1000 correct (81.10%)\n",
      "\n",
      "Iteration 100, loss = 0.3649\n",
      "Checking accuracy on validation set\n",
      "Got 805 / 1000 correct (80.50%)\n",
      "\n",
      "Iteration 200, loss = 0.4358\n",
      "Checking accuracy on validation set\n",
      "Got 803 / 1000 correct (80.30%)\n",
      "\n",
      "Iteration 300, loss = 0.2393\n",
      "Checking accuracy on validation set\n",
      "Got 799 / 1000 correct (79.90%)\n",
      "\n",
      "Iteration 400, loss = 0.1770\n",
      "Checking accuracy on validation set\n",
      "Got 800 / 1000 correct (80.00%)\n",
      "\n",
      "Iteration 500, loss = 0.3650\n",
      "Checking accuracy on validation set\n",
      "Got 822 / 1000 correct (82.20%)\n",
      "\n",
      "Iteration 600, loss = 0.2045\n",
      "Checking accuracy on validation set\n",
      "Got 798 / 1000 correct (79.80%)\n",
      "\n",
      "Iteration 700, loss = 0.4311\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80%)\n",
      "\n",
      "Iteration 0, loss = 0.3074\n",
      "Checking accuracy on validation set\n",
      "Got 791 / 1000 correct (79.10%)\n",
      "\n",
      "Iteration 100, loss = 0.1914\n",
      "Checking accuracy on validation set\n",
      "Got 815 / 1000 correct (81.50%)\n",
      "\n",
      "Iteration 200, loss = 0.3085\n",
      "Checking accuracy on validation set\n",
      "Got 835 / 1000 correct (83.50%)\n",
      "\n",
      "Iteration 300, loss = 0.2722\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60%)\n",
      "\n",
      "Iteration 400, loss = 0.4119\n",
      "Checking accuracy on validation set\n",
      "Got 814 / 1000 correct (81.40%)\n",
      "\n",
      "Iteration 500, loss = 0.3563\n",
      "Checking accuracy on validation set\n",
      "Got 805 / 1000 correct (80.50%)\n",
      "\n",
      "Iteration 600, loss = 0.3321\n",
      "Checking accuracy on validation set\n",
      "Got 804 / 1000 correct (80.40%)\n",
      "\n",
      "Iteration 700, loss = 0.2727\n",
      "Checking accuracy on validation set\n",
      "Got 815 / 1000 correct (81.50%)\n",
      "\n",
      "Iteration 0, loss = 0.2613\n",
      "Checking accuracy on validation set\n",
      "Got 811 / 1000 correct (81.10%)\n",
      "\n",
      "Iteration 100, loss = 0.3600\n",
      "Checking accuracy on validation set\n",
      "Got 822 / 1000 correct (82.20%)\n",
      "\n",
      "Iteration 200, loss = 0.2615\n",
      "Checking accuracy on validation set\n",
      "Got 816 / 1000 correct (81.60%)\n",
      "\n",
      "Iteration 300, loss = 0.2761\n",
      "Checking accuracy on validation set\n",
      "Got 822 / 1000 correct (82.20%)\n",
      "\n",
      "Iteration 400, loss = 0.2631\n",
      "Checking accuracy on validation set\n",
      "Got 823 / 1000 correct (82.30%)\n",
      "\n",
      "Iteration 500, loss = 0.2722\n",
      "Checking accuracy on validation set\n",
      "Got 796 / 1000 correct (79.60%)\n",
      "\n",
      "Iteration 600, loss = 0.1722\n",
      "Checking accuracy on validation set\n",
      "Got 817 / 1000 correct (81.70%)\n",
      "\n",
      "Iteration 700, loss = 0.3153\n",
      "Checking accuracy on validation set\n",
      "Got 821 / 1000 correct (82.10%)\n",
      "\n",
      "Checking accuracy on test set\n",
      "Got 8054 / 10000 correct (80.54%)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8054, tensor(8054, device='cuda:0'), 10000)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_A = None\n",
    "optimizer = None\n",
    "\n",
    "#learning_rate = [0.25,0.1,0.05,0.01]\n",
    "class AConv(nn.Module):\n",
    "    def __init__(self,input_size,n_classes=10,**kwargs):\n",
    "        super(AConv,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(input_size,96,5,padding=2)\n",
    "        \n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=3,stride=2)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(96,192,5,padding=2)\n",
    "        \n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=3,stride=2)\n",
    "        \n",
    "        \n",
    "        self.conv5 = nn.Conv2d(192,192,3,padding=1)\n",
    "        self.conv8 = nn.Conv2d(192,192,1,padding=0)\n",
    "        self.class_conv = nn.Conv2d(192,n_classes,1,padding=0)\n",
    "        \n",
    "        \n",
    "    def forward(self,x):\n",
    "        x_drop = F.dropout(x,0.2)\n",
    "        conv1_out = F.relu(self.conv1(x))\n",
    "        \n",
    "        conv3_out = F.relu(self.conv3(F.dropout(self.pool2(conv1_out),0.5)))       \n",
    "        \n",
    "        conv5_out = F.relu(self.conv5(F.dropout(self.pool4(conv3_out),0.5)))        \n",
    "        \n",
    "        conv8_out = F.relu(self.conv8(conv5_out)) \n",
    "        \n",
    "        class_out = F.relu(self.class_conv(conv8_out))\n",
    "        \n",
    "        pool_out = F.avg_pool2d(class_out,kernel_size=6)\n",
    "        pool_out.squeeze_(-1)\n",
    "        pool_out.squeeze_(-1)\n",
    "        \n",
    "        return pool_out\n",
    "\n",
    "#for i in range(4):\n",
    "    #lr = learning_rate[i]\n",
    "    \n",
    "model_A = None\n",
    "optimizer = None\n",
    "    \n",
    "model_A = AConv(3)   \n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model_A.parameters(), lr=0.01,momentum=0.9, weight_decay=0.001,nesterov=True)\n",
    "\n",
    "#train(model_A, optimizer, epochs=200)   \n",
    "\n",
    "#optimizer = optim.SGD(model_A.parameters(), lr=lr*0.1,momentum=0.9,weight_decay=0.001,nesterov=True)\n",
    "\n",
    "#train(model_A, optimizer, epochs=50)\n",
    "\n",
    "#optimizer = optim.SGD(model_A.parameters(), lr=lr*0.1, momentum=0.9,weight_decay=0.001,nesterov=True)\n",
    "\n",
    "#train(model_A, optimizer, epochs=50)\n",
    "#optimizer = optim.SGD(model_A.parameters(), lr=lr*0.1,momentum=0.9,weight_decay=0.001,nesterov=True)\n",
    "\n",
    "train(model_A, optimizer, epochs=20)\n",
    "check_accuracy(loader_test, model_A.cuda()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "x1 = range(0,20)\n",
    "x2 = range(0,20)\n",
    "y1 = Accuracy_list#[x*767 for x in Accuracy_list]\n",
    "y2 = Loss_list#[x*767 for x in Loss_list]\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(x1, y1, 'o-')\n",
    "plt.title('Accuracy vs. epoches')\n",
    "plt.ylabel('train accuracy')\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(x2, y2, '.-')\n",
    "plt.xlabel('train loss vs. epoches')\n",
    "plt.ylabel('train loss')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, loss = 2.2991\n",
      "Checking accuracy on validation set\n",
      "Got 127 / 1000 correct (12.70%)\n",
      "\n",
      "Iteration 100, loss = 2.2988\n",
      "Checking accuracy on validation set\n",
      "Got 105 / 1000 correct (10.50%)\n",
      "\n",
      "Iteration 200, loss = 2.2932\n",
      "Checking accuracy on validation set\n",
      "Got 202 / 1000 correct (20.20%)\n",
      "\n",
      "Iteration 300, loss = 2.2324\n",
      "Checking accuracy on validation set\n",
      "Got 213 / 1000 correct (21.30%)\n",
      "\n",
      "Iteration 400, loss = 2.1691\n",
      "Checking accuracy on validation set\n",
      "Got 247 / 1000 correct (24.70%)\n",
      "\n",
      "Iteration 500, loss = 2.1215\n",
      "Checking accuracy on validation set\n",
      "Got 268 / 1000 correct (26.80%)\n",
      "\n",
      "Iteration 600, loss = 2.0560\n",
      "Checking accuracy on validation set\n",
      "Got 303 / 1000 correct (30.30%)\n",
      "\n",
      "Iteration 700, loss = 1.9257\n",
      "Checking accuracy on validation set\n",
      "Got 302 / 1000 correct (30.20%)\n",
      "\n",
      "Iteration 0, loss = 1.9897\n",
      "Checking accuracy on validation set\n",
      "Got 328 / 1000 correct (32.80%)\n",
      "\n",
      "Iteration 100, loss = 1.9151\n",
      "Checking accuracy on validation set\n",
      "Got 348 / 1000 correct (34.80%)\n",
      "\n",
      "Iteration 200, loss = 1.8925\n",
      "Checking accuracy on validation set\n",
      "Got 338 / 1000 correct (33.80%)\n",
      "\n",
      "Iteration 300, loss = 1.8689\n",
      "Checking accuracy on validation set\n",
      "Got 359 / 1000 correct (35.90%)\n",
      "\n",
      "Iteration 400, loss = 1.9179\n",
      "Checking accuracy on validation set\n",
      "Got 338 / 1000 correct (33.80%)\n",
      "\n",
      "Iteration 500, loss = 1.5722\n",
      "Checking accuracy on validation set\n",
      "Got 374 / 1000 correct (37.40%)\n",
      "\n",
      "Iteration 600, loss = 1.7523\n",
      "Checking accuracy on validation set\n",
      "Got 371 / 1000 correct (37.10%)\n",
      "\n",
      "Iteration 700, loss = 1.5490\n",
      "Checking accuracy on validation set\n",
      "Got 399 / 1000 correct (39.90%)\n",
      "\n",
      "Iteration 0, loss = 1.6241\n",
      "Checking accuracy on validation set\n",
      "Got 396 / 1000 correct (39.60%)\n",
      "\n",
      "Iteration 100, loss = 1.6784\n",
      "Checking accuracy on validation set\n",
      "Got 404 / 1000 correct (40.40%)\n",
      "\n",
      "Iteration 200, loss = 1.8492\n",
      "Checking accuracy on validation set\n",
      "Got 433 / 1000 correct (43.30%)\n",
      "\n",
      "Iteration 300, loss = 1.8156\n",
      "Checking accuracy on validation set\n",
      "Got 433 / 1000 correct (43.30%)\n",
      "\n",
      "Iteration 400, loss = 1.2658\n",
      "Checking accuracy on validation set\n",
      "Got 429 / 1000 correct (42.90%)\n",
      "\n",
      "Iteration 500, loss = 1.3634\n",
      "Checking accuracy on validation set\n",
      "Got 461 / 1000 correct (46.10%)\n",
      "\n",
      "Iteration 600, loss = 1.6465\n",
      "Checking accuracy on validation set\n",
      "Got 455 / 1000 correct (45.50%)\n",
      "\n",
      "Iteration 700, loss = 1.2910\n",
      "Checking accuracy on validation set\n",
      "Got 469 / 1000 correct (46.90%)\n",
      "\n",
      "Iteration 0, loss = 1.6040\n",
      "Checking accuracy on validation set\n",
      "Got 483 / 1000 correct (48.30%)\n",
      "\n",
      "Iteration 100, loss = 1.4485\n",
      "Checking accuracy on validation set\n",
      "Got 467 / 1000 correct (46.70%)\n",
      "\n",
      "Iteration 200, loss = 1.5018\n",
      "Checking accuracy on validation set\n",
      "Got 513 / 1000 correct (51.30%)\n",
      "\n",
      "Iteration 300, loss = 1.3371\n",
      "Checking accuracy on validation set\n",
      "Got 507 / 1000 correct (50.70%)\n",
      "\n",
      "Iteration 400, loss = 1.1974\n",
      "Checking accuracy on validation set\n",
      "Got 504 / 1000 correct (50.40%)\n",
      "\n",
      "Iteration 500, loss = 1.4305\n",
      "Checking accuracy on validation set\n",
      "Got 511 / 1000 correct (51.10%)\n",
      "\n",
      "Iteration 600, loss = 1.3947\n",
      "Checking accuracy on validation set\n",
      "Got 527 / 1000 correct (52.70%)\n",
      "\n",
      "Iteration 700, loss = 1.2151\n",
      "Checking accuracy on validation set\n",
      "Got 559 / 1000 correct (55.90%)\n",
      "\n",
      "Iteration 0, loss = 1.2570\n",
      "Checking accuracy on validation set\n",
      "Got 524 / 1000 correct (52.40%)\n",
      "\n",
      "Iteration 100, loss = 1.4552\n",
      "Checking accuracy on validation set\n",
      "Got 504 / 1000 correct (50.40%)\n",
      "\n",
      "Iteration 200, loss = 1.3633\n",
      "Checking accuracy on validation set\n",
      "Got 535 / 1000 correct (53.50%)\n",
      "\n",
      "Iteration 300, loss = 1.0635\n",
      "Checking accuracy on validation set\n",
      "Got 542 / 1000 correct (54.20%)\n",
      "\n",
      "Iteration 400, loss = 1.2807\n",
      "Checking accuracy on validation set\n",
      "Got 551 / 1000 correct (55.10%)\n",
      "\n",
      "Iteration 500, loss = 1.4882\n",
      "Checking accuracy on validation set\n",
      "Got 530 / 1000 correct (53.00%)\n",
      "\n",
      "Iteration 600, loss = 1.1057\n",
      "Checking accuracy on validation set\n",
      "Got 536 / 1000 correct (53.60%)\n",
      "\n",
      "Iteration 700, loss = 1.1945\n",
      "Checking accuracy on validation set\n",
      "Got 542 / 1000 correct (54.20%)\n",
      "\n",
      "Iteration 0, loss = 0.9117\n",
      "Checking accuracy on validation set\n",
      "Got 563 / 1000 correct (56.30%)\n",
      "\n",
      "Iteration 100, loss = 1.1241\n",
      "Checking accuracy on validation set\n",
      "Got 570 / 1000 correct (57.00%)\n",
      "\n",
      "Iteration 200, loss = 1.2438\n",
      "Checking accuracy on validation set\n",
      "Got 539 / 1000 correct (53.90%)\n",
      "\n",
      "Iteration 300, loss = 0.8228\n",
      "Checking accuracy on validation set\n",
      "Got 557 / 1000 correct (55.70%)\n",
      "\n",
      "Iteration 400, loss = 1.1173\n",
      "Checking accuracy on validation set\n",
      "Got 570 / 1000 correct (57.00%)\n",
      "\n",
      "Iteration 500, loss = 1.1436\n",
      "Checking accuracy on validation set\n",
      "Got 585 / 1000 correct (58.50%)\n",
      "\n",
      "Iteration 600, loss = 1.0671\n",
      "Checking accuracy on validation set\n",
      "Got 545 / 1000 correct (54.50%)\n",
      "\n",
      "Iteration 700, loss = 1.1211\n",
      "Checking accuracy on validation set\n",
      "Got 579 / 1000 correct (57.90%)\n",
      "\n",
      "Iteration 0, loss = 1.5059\n",
      "Checking accuracy on validation set\n",
      "Got 594 / 1000 correct (59.40%)\n",
      "\n",
      "Iteration 100, loss = 1.1104\n",
      "Checking accuracy on validation set\n",
      "Got 581 / 1000 correct (58.10%)\n",
      "\n",
      "Iteration 200, loss = 1.2209\n",
      "Checking accuracy on validation set\n",
      "Got 582 / 1000 correct (58.20%)\n",
      "\n",
      "Iteration 300, loss = 1.0674\n",
      "Checking accuracy on validation set\n",
      "Got 608 / 1000 correct (60.80%)\n",
      "\n",
      "Iteration 400, loss = 0.9835\n",
      "Checking accuracy on validation set\n",
      "Got 596 / 1000 correct (59.60%)\n",
      "\n",
      "Iteration 500, loss = 1.0650\n",
      "Checking accuracy on validation set\n",
      "Got 589 / 1000 correct (58.90%)\n",
      "\n",
      "Iteration 600, loss = 1.0861\n",
      "Checking accuracy on validation set\n",
      "Got 608 / 1000 correct (60.80%)\n",
      "\n",
      "Iteration 700, loss = 1.3242\n",
      "Checking accuracy on validation set\n",
      "Got 586 / 1000 correct (58.60%)\n",
      "\n",
      "Iteration 0, loss = 0.7958\n",
      "Checking accuracy on validation set\n",
      "Got 600 / 1000 correct (60.00%)\n",
      "\n",
      "Iteration 100, loss = 1.1989\n",
      "Checking accuracy on validation set\n",
      "Got 604 / 1000 correct (60.40%)\n",
      "\n",
      "Iteration 200, loss = 0.7874\n",
      "Checking accuracy on validation set\n",
      "Got 612 / 1000 correct (61.20%)\n",
      "\n",
      "Iteration 300, loss = 1.2523\n",
      "Checking accuracy on validation set\n",
      "Got 634 / 1000 correct (63.40%)\n",
      "\n",
      "Iteration 400, loss = 0.9873\n",
      "Checking accuracy on validation set\n",
      "Got 636 / 1000 correct (63.60%)\n",
      "\n",
      "Iteration 500, loss = 0.9867\n",
      "Checking accuracy on validation set\n",
      "Got 640 / 1000 correct (64.00%)\n",
      "\n",
      "Iteration 600, loss = 0.7873\n",
      "Checking accuracy on validation set\n",
      "Got 627 / 1000 correct (62.70%)\n",
      "\n",
      "Iteration 700, loss = 0.7845\n",
      "Checking accuracy on validation set\n",
      "Got 632 / 1000 correct (63.20%)\n",
      "\n",
      "Iteration 0, loss = 0.9786\n",
      "Checking accuracy on validation set\n",
      "Got 636 / 1000 correct (63.60%)\n",
      "\n",
      "Iteration 100, loss = 0.8042\n",
      "Checking accuracy on validation set\n",
      "Got 639 / 1000 correct (63.90%)\n",
      "\n",
      "Iteration 200, loss = 0.9493\n",
      "Checking accuracy on validation set\n",
      "Got 626 / 1000 correct (62.60%)\n",
      "\n",
      "Iteration 300, loss = 0.8655\n",
      "Checking accuracy on validation set\n",
      "Got 637 / 1000 correct (63.70%)\n",
      "\n",
      "Iteration 400, loss = 0.8776\n",
      "Checking accuracy on validation set\n",
      "Got 649 / 1000 correct (64.90%)\n",
      "\n",
      "Iteration 500, loss = 0.8641\n",
      "Checking accuracy on validation set\n",
      "Got 640 / 1000 correct (64.00%)\n",
      "\n",
      "Iteration 600, loss = 1.1665\n",
      "Checking accuracy on validation set\n",
      "Got 647 / 1000 correct (64.70%)\n",
      "\n",
      "Iteration 700, loss = 1.1093\n",
      "Checking accuracy on validation set\n",
      "Got 626 / 1000 correct (62.60%)\n",
      "\n",
      "Iteration 0, loss = 1.0401\n",
      "Checking accuracy on validation set\n",
      "Got 648 / 1000 correct (64.80%)\n",
      "\n",
      "Iteration 100, loss = 0.7770\n",
      "Checking accuracy on validation set\n",
      "Got 660 / 1000 correct (66.00%)\n",
      "\n",
      "Iteration 200, loss = 0.9574\n",
      "Checking accuracy on validation set\n",
      "Got 655 / 1000 correct (65.50%)\n",
      "\n",
      "Iteration 300, loss = 1.1381\n",
      "Checking accuracy on validation set\n",
      "Got 641 / 1000 correct (64.10%)\n",
      "\n",
      "Iteration 400, loss = 0.8938\n",
      "Checking accuracy on validation set\n",
      "Got 654 / 1000 correct (65.40%)\n",
      "\n",
      "Iteration 500, loss = 0.9080\n",
      "Checking accuracy on validation set\n",
      "Got 641 / 1000 correct (64.10%)\n",
      "\n",
      "Iteration 600, loss = 0.9136\n",
      "Checking accuracy on validation set\n",
      "Got 650 / 1000 correct (65.00%)\n",
      "\n",
      "Iteration 700, loss = 0.9246\n",
      "Checking accuracy on validation set\n",
      "Got 639 / 1000 correct (63.90%)\n",
      "\n",
      "Iteration 0, loss = 0.6880\n",
      "Checking accuracy on validation set\n",
      "Got 676 / 1000 correct (67.60%)\n",
      "\n",
      "Iteration 100, loss = 0.7874\n",
      "Checking accuracy on validation set\n",
      "Got 647 / 1000 correct (64.70%)\n",
      "\n",
      "Iteration 200, loss = 0.7874\n",
      "Checking accuracy on validation set\n",
      "Got 676 / 1000 correct (67.60%)\n",
      "\n",
      "Iteration 300, loss = 0.7940\n",
      "Checking accuracy on validation set\n",
      "Got 676 / 1000 correct (67.60%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 400, loss = 1.0261\n",
      "Checking accuracy on validation set\n",
      "Got 665 / 1000 correct (66.50%)\n",
      "\n",
      "Iteration 500, loss = 0.7708\n",
      "Checking accuracy on validation set\n",
      "Got 650 / 1000 correct (65.00%)\n",
      "\n",
      "Iteration 600, loss = 0.8550\n",
      "Checking accuracy on validation set\n",
      "Got 661 / 1000 correct (66.10%)\n",
      "\n",
      "Iteration 700, loss = 0.8850\n",
      "Checking accuracy on validation set\n",
      "Got 627 / 1000 correct (62.70%)\n",
      "\n",
      "Iteration 0, loss = 0.7849\n",
      "Checking accuracy on validation set\n",
      "Got 665 / 1000 correct (66.50%)\n",
      "\n",
      "Iteration 100, loss = 0.7862\n",
      "Checking accuracy on validation set\n",
      "Got 666 / 1000 correct (66.60%)\n",
      "\n",
      "Iteration 200, loss = 0.5651\n",
      "Checking accuracy on validation set\n",
      "Got 675 / 1000 correct (67.50%)\n",
      "\n",
      "Iteration 300, loss = 0.7660\n",
      "Checking accuracy on validation set\n",
      "Got 675 / 1000 correct (67.50%)\n",
      "\n",
      "Iteration 400, loss = 0.6365\n",
      "Checking accuracy on validation set\n",
      "Got 675 / 1000 correct (67.50%)\n",
      "\n",
      "Iteration 500, loss = 0.7206\n",
      "Checking accuracy on validation set\n",
      "Got 671 / 1000 correct (67.10%)\n",
      "\n",
      "Iteration 600, loss = 0.9269\n",
      "Checking accuracy on validation set\n",
      "Got 667 / 1000 correct (66.70%)\n",
      "\n",
      "Iteration 700, loss = 0.6376\n",
      "Checking accuracy on validation set\n",
      "Got 666 / 1000 correct (66.60%)\n",
      "\n",
      "Iteration 0, loss = 0.8126\n",
      "Checking accuracy on validation set\n",
      "Got 680 / 1000 correct (68.00%)\n",
      "\n",
      "Iteration 100, loss = 0.8250\n",
      "Checking accuracy on validation set\n",
      "Got 673 / 1000 correct (67.30%)\n",
      "\n",
      "Iteration 200, loss = 0.8678\n",
      "Checking accuracy on validation set\n",
      "Got 672 / 1000 correct (67.20%)\n",
      "\n",
      "Iteration 300, loss = 0.8621\n",
      "Checking accuracy on validation set\n",
      "Got 671 / 1000 correct (67.10%)\n",
      "\n",
      "Iteration 400, loss = 0.7998\n",
      "Checking accuracy on validation set\n",
      "Got 680 / 1000 correct (68.00%)\n",
      "\n",
      "Iteration 500, loss = 0.5105\n",
      "Checking accuracy on validation set\n",
      "Got 674 / 1000 correct (67.40%)\n",
      "\n",
      "Iteration 600, loss = 0.5496\n",
      "Checking accuracy on validation set\n",
      "Got 687 / 1000 correct (68.70%)\n",
      "\n",
      "Iteration 700, loss = 0.8926\n",
      "Checking accuracy on validation set\n",
      "Got 691 / 1000 correct (69.10%)\n",
      "\n",
      "Iteration 0, loss = 0.6091\n",
      "Checking accuracy on validation set\n",
      "Got 668 / 1000 correct (66.80%)\n",
      "\n",
      "Iteration 100, loss = 0.8269\n",
      "Checking accuracy on validation set\n",
      "Got 678 / 1000 correct (67.80%)\n",
      "\n",
      "Iteration 200, loss = 0.5893\n",
      "Checking accuracy on validation set\n",
      "Got 684 / 1000 correct (68.40%)\n",
      "\n",
      "Iteration 300, loss = 0.7590\n",
      "Checking accuracy on validation set\n",
      "Got 661 / 1000 correct (66.10%)\n",
      "\n",
      "Iteration 400, loss = 0.8151\n",
      "Checking accuracy on validation set\n",
      "Got 683 / 1000 correct (68.30%)\n",
      "\n",
      "Iteration 500, loss = 0.7362\n",
      "Checking accuracy on validation set\n",
      "Got 645 / 1000 correct (64.50%)\n",
      "\n",
      "Iteration 600, loss = 0.8769\n",
      "Checking accuracy on validation set\n",
      "Got 668 / 1000 correct (66.80%)\n",
      "\n",
      "Iteration 700, loss = 0.5875\n",
      "Checking accuracy on validation set\n",
      "Got 690 / 1000 correct (69.00%)\n",
      "\n",
      "Iteration 0, loss = 0.8173\n",
      "Checking accuracy on validation set\n",
      "Got 701 / 1000 correct (70.10%)\n",
      "\n",
      "Iteration 100, loss = 0.7124\n",
      "Checking accuracy on validation set\n",
      "Got 694 / 1000 correct (69.40%)\n",
      "\n",
      "Iteration 200, loss = 0.6674\n",
      "Checking accuracy on validation set\n",
      "Got 692 / 1000 correct (69.20%)\n",
      "\n",
      "Iteration 300, loss = 0.6448\n",
      "Checking accuracy on validation set\n",
      "Got 692 / 1000 correct (69.20%)\n",
      "\n",
      "Iteration 400, loss = 0.8610\n",
      "Checking accuracy on validation set\n",
      "Got 690 / 1000 correct (69.00%)\n",
      "\n",
      "Iteration 500, loss = 0.5598\n",
      "Checking accuracy on validation set\n",
      "Got 682 / 1000 correct (68.20%)\n",
      "\n",
      "Iteration 600, loss = 0.7482\n",
      "Checking accuracy on validation set\n",
      "Got 701 / 1000 correct (70.10%)\n",
      "\n",
      "Iteration 700, loss = 0.7356\n",
      "Checking accuracy on validation set\n",
      "Got 676 / 1000 correct (67.60%)\n",
      "\n",
      "Iteration 0, loss = 0.7472\n",
      "Checking accuracy on validation set\n",
      "Got 680 / 1000 correct (68.00%)\n",
      "\n",
      "Iteration 100, loss = 0.6778\n",
      "Checking accuracy on validation set\n",
      "Got 698 / 1000 correct (69.80%)\n",
      "\n",
      "Iteration 200, loss = 0.5507\n",
      "Checking accuracy on validation set\n",
      "Got 690 / 1000 correct (69.00%)\n",
      "\n",
      "Iteration 300, loss = 0.5621\n",
      "Checking accuracy on validation set\n",
      "Got 694 / 1000 correct (69.40%)\n",
      "\n",
      "Iteration 400, loss = 0.4293\n",
      "Checking accuracy on validation set\n",
      "Got 693 / 1000 correct (69.30%)\n",
      "\n",
      "Iteration 500, loss = 0.5711\n",
      "Checking accuracy on validation set\n",
      "Got 693 / 1000 correct (69.30%)\n",
      "\n",
      "Iteration 600, loss = 0.7886\n",
      "Checking accuracy on validation set\n",
      "Got 694 / 1000 correct (69.40%)\n",
      "\n",
      "Iteration 700, loss = 0.7150\n",
      "Checking accuracy on validation set\n",
      "Got 684 / 1000 correct (68.40%)\n",
      "\n",
      "Iteration 0, loss = 0.5820\n",
      "Checking accuracy on validation set\n",
      "Got 657 / 1000 correct (65.70%)\n",
      "\n",
      "Iteration 100, loss = 0.6272\n",
      "Checking accuracy on validation set\n",
      "Got 709 / 1000 correct (70.90%)\n",
      "\n",
      "Iteration 200, loss = 0.4459\n",
      "Checking accuracy on validation set\n",
      "Got 671 / 1000 correct (67.10%)\n",
      "\n",
      "Iteration 300, loss = 0.5660\n",
      "Checking accuracy on validation set\n",
      "Got 692 / 1000 correct (69.20%)\n",
      "\n",
      "Iteration 400, loss = 0.7016\n",
      "Checking accuracy on validation set\n",
      "Got 699 / 1000 correct (69.90%)\n",
      "\n",
      "Iteration 500, loss = 0.6553\n",
      "Checking accuracy on validation set\n",
      "Got 687 / 1000 correct (68.70%)\n",
      "\n",
      "Iteration 600, loss = 0.6721\n",
      "Checking accuracy on validation set\n",
      "Got 682 / 1000 correct (68.20%)\n",
      "\n",
      "Iteration 700, loss = 0.5977\n",
      "Checking accuracy on validation set\n",
      "Got 701 / 1000 correct (70.10%)\n",
      "\n",
      "Iteration 0, loss = 0.6293\n",
      "Checking accuracy on validation set\n",
      "Got 698 / 1000 correct (69.80%)\n",
      "\n",
      "Iteration 100, loss = 0.6978\n",
      "Checking accuracy on validation set\n",
      "Got 687 / 1000 correct (68.70%)\n",
      "\n",
      "Iteration 200, loss = 0.7070\n",
      "Checking accuracy on validation set\n",
      "Got 700 / 1000 correct (70.00%)\n",
      "\n",
      "Iteration 300, loss = 0.6815\n",
      "Checking accuracy on validation set\n",
      "Got 705 / 1000 correct (70.50%)\n",
      "\n",
      "Iteration 400, loss = 0.9194\n",
      "Checking accuracy on validation set\n",
      "Got 695 / 1000 correct (69.50%)\n",
      "\n",
      "Iteration 500, loss = 0.5824\n",
      "Checking accuracy on validation set\n",
      "Got 700 / 1000 correct (70.00%)\n",
      "\n",
      "Iteration 600, loss = 0.8937\n",
      "Checking accuracy on validation set\n",
      "Got 690 / 1000 correct (69.00%)\n",
      "\n",
      "Iteration 700, loss = 0.7108\n",
      "Checking accuracy on validation set\n",
      "Got 685 / 1000 correct (68.50%)\n",
      "\n",
      "Iteration 0, loss = 0.4358\n",
      "Checking accuracy on validation set\n",
      "Got 698 / 1000 correct (69.80%)\n",
      "\n",
      "Iteration 100, loss = 0.6957\n",
      "Checking accuracy on validation set\n",
      "Got 706 / 1000 correct (70.60%)\n",
      "\n",
      "Iteration 200, loss = 0.3229\n",
      "Checking accuracy on validation set\n",
      "Got 670 / 1000 correct (67.00%)\n",
      "\n",
      "Iteration 300, loss = 0.6624\n",
      "Checking accuracy on validation set\n",
      "Got 695 / 1000 correct (69.50%)\n",
      "\n",
      "Iteration 400, loss = 0.8801\n",
      "Checking accuracy on validation set\n",
      "Got 696 / 1000 correct (69.60%)\n",
      "\n",
      "Iteration 500, loss = 0.4272\n",
      "Checking accuracy on validation set\n",
      "Got 684 / 1000 correct (68.40%)\n",
      "\n",
      "Iteration 600, loss = 0.4498\n",
      "Checking accuracy on validation set\n",
      "Got 694 / 1000 correct (69.40%)\n",
      "\n",
      "Iteration 700, loss = 0.6376\n",
      "Checking accuracy on validation set\n",
      "Got 696 / 1000 correct (69.60%)\n",
      "\n",
      "Iteration 0, loss = 0.7436\n",
      "Checking accuracy on validation set\n",
      "Got 686 / 1000 correct (68.60%)\n",
      "\n",
      "Iteration 100, loss = 0.4642\n",
      "Checking accuracy on validation set\n",
      "Got 696 / 1000 correct (69.60%)\n",
      "\n",
      "Iteration 200, loss = 0.5342\n",
      "Checking accuracy on validation set\n",
      "Got 710 / 1000 correct (71.00%)\n",
      "\n",
      "Iteration 300, loss = 0.4562\n",
      "Checking accuracy on validation set\n",
      "Got 691 / 1000 correct (69.10%)\n",
      "\n",
      "Iteration 400, loss = 0.6078\n",
      "Checking accuracy on validation set\n",
      "Got 701 / 1000 correct (70.10%)\n",
      "\n",
      "Iteration 500, loss = 0.4805\n",
      "Checking accuracy on validation set\n",
      "Got 696 / 1000 correct (69.60%)\n",
      "\n",
      "Iteration 600, loss = 0.6775\n",
      "Checking accuracy on validation set\n",
      "Got 705 / 1000 correct (70.50%)\n",
      "\n",
      "Iteration 700, loss = 0.5701\n",
      "Checking accuracy on validation set\n",
      "Got 674 / 1000 correct (67.40%)\n",
      "\n",
      "Checking accuracy on test set\n",
      "Got 6982 / 10000 correct (69.82%)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6982, tensor(6982, device='cuda:0'), 10000)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_B = None\n",
    "optimizer = None\n",
    "class BConv(nn.Module):\n",
    "    def __init__(self,input_size,n_classes=10,**kwargs):\n",
    "        super(BConv,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(input_size,96,5,padding=2)\n",
    "        self.conv2 = nn.Conv2d(96,96,1,padding=0)\n",
    "        \n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=3,stride=2)\n",
    "        \n",
    "        \n",
    "        self.conv4 = nn.Conv2d(96,192,5,padding=2)\n",
    "        self.conv5 = nn.Conv2d(192,192,1,padding=0)\n",
    "        \n",
    "        self.pool6 = nn.MaxPool2d(kernel_size=3,stride=2)\n",
    "        \n",
    "        \n",
    "        self.conv7 = nn.Conv2d(192,192,3,padding=1)\n",
    "        self.conv8 = nn.Conv2d(192,192,1,padding=0)\n",
    "        self.class_conv = nn.Conv2d(192,n_classes,1,padding=0)\n",
    "        \n",
    "        \n",
    "    def forward(self,x):\n",
    "        \n",
    "        #add drop\n",
    "        x_drop = F.dropout(x,0.2)\n",
    "        conv1_out = F.relu(self.conv1(x_drop))\n",
    "        conv2_out = F.relu(self.conv2(conv1_out))\n",
    "        \n",
    "        conv4_out = F.relu(self.conv4(F.dropout(self.pool3(conv2_out),0.5)))        \n",
    "        conv5_out = F.relu(self.conv5(conv4_out))\n",
    "        \n",
    "        conv7_out = F.relu(self.conv7(F.dropout(self.pool6(conv5_out),0.5)))\n",
    "        conv8_out = F.relu(self.conv8(conv7_out))   \n",
    "        class_out = F.relu(self.class_conv(conv8_out))\n",
    "        \n",
    "        pool_out = F.avg_pool2d(class_out,kernel_size=6)\n",
    "        pool_out.squeeze_(-1)\n",
    "        pool_out.squeeze_(-1)\n",
    "        \n",
    "        return pool_out\n",
    "\n",
    "model_B = BConv(3)\n",
    "       \n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.SGD(model_B.parameters(), lr=0.01,\n",
    "                     momentum=0.9, weight_decay=0.001 , nesterov=True)\n",
    "\n",
    "train(model_B, optimizer, epochs=20)        \n",
    "\n",
    "check_accuracy(loader_test, model_B.cuda())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "x1 = range(0,20)\n",
    "x2 = range(0,20)\n",
    "y1 = Accuracy_list\n",
    "y2 = Loss_list\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(x1, y1, 'o-')\n",
    "plt.title('Accuracy vs. epoches')\n",
    "plt.ylabel('train accuracy')\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(x2, y2, '.-')\n",
    "plt.xlabel('train loss vs. epoches')\n",
    "plt.ylabel('train loss')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_C = None\n",
    "optimizer = None\n",
    "\n",
    "class CConv(nn.Module):\n",
    "    def __init__(self,input_size,n_classes=10,**kwargs):\n",
    "        super(CConv,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(input_size,96,3,padding=1)\n",
    "        self.conv2 = nn.Conv2d(96,96,3,padding=1)\n",
    "        \n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=3,stride=2)\n",
    "        \n",
    "        self.conv4 = nn.Conv2d(96,192,3,padding=1)\n",
    "        self.conv5 = nn.Conv2d(192,192,3,padding=1)\n",
    "        \n",
    "        self.pool6 = nn.MaxPool2d(kernel_size=3,stride=2)\n",
    "        \n",
    "        self.conv7 = nn.Conv2d(192,192,3,padding=1)\n",
    "        self.conv8 = nn.Conv2d(192,192,1,padding=0)\n",
    "        self.class_conv = nn.Conv2d(192,n_classes,1,padding=0)\n",
    "        \n",
    "        \n",
    "    def forward(self,x):\n",
    "        \n",
    "        #add drop\n",
    "        x_drop = F.dropout(x,0.2)\n",
    "        conv1_out = F.relu(self.conv1(x_drop))\n",
    "        conv2_out = F.relu(self.conv2(conv1_out))\n",
    "        \n",
    "        conv4_out = F.relu(self.conv4(F.dropout(self.pool3(conv2_out),0.5)))                    \n",
    "        conv5_out = F.relu(self.conv5(conv4_out))\n",
    "        \n",
    "        conv7_out = F.relu(self.conv7(F.dropout(self.pool6(conv5_out),0.5)))\n",
    "        conv8_out = F.relu(self.conv8(conv7_out))   \n",
    "        class_out = F.relu(self.class_conv(conv8_out))\n",
    "        \n",
    "        pool_out = F.avg_pool2d(class_out,kernel_size=6)\n",
    "        pool_out.squeeze_(-1)\n",
    "        pool_out.squeeze_(-1)\n",
    "        \n",
    "        return pool_out\n",
    "\n",
    "model_C = CConv(3)\n",
    "       \n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "                           \n",
    "optimizer = optim.SGD(model_C.parameters(), lr=0.01,\n",
    "                     momentum=0.9, weight_decay=0.001 ,nesterov=True)\n",
    "\n",
    "train(model_C, optimizer, epochs=20)        \n",
    "        \n",
    "check_accuracy(loader_test, model_C.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Loss_list = []\n",
    "Accuracy_list = []\n",
    "import matplotlib.pyplot as plt\n",
    "x1 = range(0,20)\n",
    "x2 = range(0,20)\n",
    "y1 = Accuracy_list#[x*767 for x in Accuracy_list]\n",
    "y2 = Loss_list#[x*767 for x in Loss_list]\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(x1, y1, 'o-')\n",
    "plt.title('Accuracy vs. epoches')\n",
    "plt.ylabel('train accuracy')\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(x2, y2, '.-')\n",
    "plt.xlabel('train loss vs. epoches')\n",
    "plt.ylabel('train loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_STRIDED = None\n",
    "optimizer = None\n",
    "\n",
    "class STRIDED(nn.Module):\n",
    "    def __init__(self,input_size,n_classes=10,**kwargs):\n",
    "        super(STRIDED,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(input_size,96,3,padding=1)\n",
    "        self.conv2 = nn.Conv2d(96,96,3,stride=2,padding=1)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(96,192,3,padding=1)\n",
    "        self.conv4 = nn.Conv2d(192,192,3,stride=2,padding=1)\n",
    "        \n",
    "        self.conv5 = nn.Conv2d(192,192,3,padding=1)\n",
    "        self.conv6 = nn.Conv2d(192,192,1,padding=0)\n",
    "        self.class_conv = nn.Conv2d(192,n_classes,1,padding=0)\n",
    "        \n",
    "        \n",
    "    def forward(self,x):\n",
    "        \n",
    "        #add drop\n",
    "        x_drop = F.dropout(x,0.2)\n",
    "        conv1_out = F.relu(self.conv1(x_drop))\n",
    "        conv2_out = F.relu(self.conv2(conv1_out))\n",
    "        conv2_out = F.dropout(conv2_out,0.5)\n",
    "        \n",
    "        conv3_out = F.relu(self.conv3(conv2_out))\n",
    "        conv4_out = F.relu(self.conv4(conv3_out))\n",
    "        conv4_out = F.dropout(conv4_out,0.5)\n",
    "        \n",
    "        conv5_out = F.relu(self.conv5(conv4_out))\n",
    "        conv6_out = F.relu(self.conv6(conv5_out))\n",
    "        \n",
    "        class_out = F.relu(self.class_conv(conv6_out))\n",
    "        \n",
    "        pool_out = F.avg_pool2d(class_out,kernel_size=6)\n",
    "        pool_out.squeeze_(-1)\n",
    "        pool_out.squeeze_(-1)\n",
    "        \n",
    "        return pool_out\n",
    "\n",
    "model_STRIDED = STRIDED(3)\n",
    "       \n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model_STRIDED.parameters(), lr=0.01,\n",
    "                     momentum=0.9,  weight_decay=0.001 ,nesterov=True)\n",
    "\n",
    "train(model_STRIDED, optimizer, epochs=20) \n",
    "\n",
    "check_accuracy(loader_test, model_STRIDED.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Loss_list = []\n",
    "Accuracy_list = []\n",
    "import matplotlib.pyplot as plt\n",
    "x1 = range(0,20)\n",
    "x2 = range(0,20)\n",
    "y1 = Accuracy_list#[x*767 for x in Accuracy_list]\n",
    "y2 = Loss_list#[x*767 for x in Loss_list]\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(x1, y1, 'o-')\n",
    "plt.title('Accuracy vs. epoches')\n",
    "plt.ylabel('train accuracy')\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(x2, y2, '.-')\n",
    "plt.xlabel('train loss vs. epoches')\n",
    "plt.ylabel('train loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ConvP = None\n",
    "optimizer = None\n",
    "from torch.nn import init\n",
    "class ConvP(nn.Module):\n",
    "    def __init__(self,input_size,n_classes=10,**kwargs):\n",
    "        super(ConvP,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(input_size,96,3,padding=1,bias=True)\n",
    "        init.xavier_uniform(self.conv1.weight, gain=np.sqrt(2.0))\n",
    "        init.constant(self.conv1.bias, 0.1)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(96,96,3,padding=1)\n",
    "        init.xavier_uniform(self.conv2.weight, gain=np.sqrt(2.0))\n",
    "        init.constant(self.conv2.bias, 0.1)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(96,96,3,padding=1)\n",
    "        init.xavier_uniform(self.conv3.weight, gain=np.sqrt(2.0))\n",
    "        init.constant(self.conv3.bias, 0.1)\n",
    "        \n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=3,stride=2)\n",
    "        \n",
    "        self.conv5 = nn.Conv2d(96,192,3,padding=1)\n",
    "        self.conv6 = nn.Conv2d(192,192,3,padding=1)\n",
    "        self.conv7 = nn.Conv2d(192,192,3,padding=1)\n",
    "        \n",
    "        self.pool8 = nn.MaxPool2d(kernel_size=3,stride=2)\n",
    "        self.conv9 = nn.Conv2d(192,192,3,padding=1)\n",
    "        self.conv10 = nn.Conv2d(192,192,1,padding=0)\n",
    "        self.class_conv = nn.Conv2d(192,n_classes,1,padding=0)\n",
    "    def forward(self,x):\n",
    "        #add drop\n",
    "        x_drop = F.dropout(x,0.2)\n",
    "        conv1_out = F.relu(self.conv1(x_drop))\n",
    "        conv2_out = F.relu(self.conv2(conv1_out))\n",
    "        conv3_out = F.relu(self.conv3(conv2_out))\n",
    "        \n",
    "        conv5_out = F.relu(self.conv5(F.dropout(self.pool4(conv3_out),0.5)))             \n",
    "        conv6_out = F.relu(self.conv6(conv5_out))\n",
    "        conv7_out = F.relu(self.conv7(conv6_out))\n",
    "        \n",
    "        conv9_out = F.relu(self.conv9(F.dropout(self.pool8(conv7_out),0.5)))  \n",
    "        conv10_out = F.relu(self.conv10(conv9_out))\n",
    "        \n",
    "        class_out = F.relu(self.class_conv(conv10_out))\n",
    "        \n",
    "        pool_out = F.avg_pool2d(class_out,kernel_size=6)\n",
    "        pool_out.squeeze_(-1)\n",
    "        pool_out.squeeze_(-1)\n",
    "        \n",
    "        return pool_out\n",
    "\n",
    "model_ConvP = ConvP(3)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model_ConvP.parameters(), lr=0.01,\n",
    "                     momentum=0.9, weight_decay=0.001 ,nesterov=True)\n",
    "\n",
    "train(model_ConvP, optimizer, epochs=20) \n",
    "\n",
    "check_accuracy(loader_test, model_ConvP.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Loss_list = []\n",
    "Accuracy_list = []\n",
    "import matplotlib.pyplot as plt\n",
    "x1 = range(0,20)\n",
    "x2 = range(0,20)\n",
    "y1 = Accuracy_list#[x*767 for x in Accuracy_list]\n",
    "y2 = Loss_list#[x*767 for x in Loss_list]\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(x1, y1, 'o-')\n",
    "plt.title('Accuracy vs. epoches')\n",
    "plt.ylabel('train accuracy')\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(x2, y2, '.-')\n",
    "plt.xlabel('train loss vs. epoches')\n",
    "plt.ylabel('train loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, loss = 2.3033\n",
      "Checking accuracy on validation set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wx/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:11: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/home/wx/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:12: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n",
      "  if sys.path[0] == '':\n",
      "/home/wx/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:15: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/wx/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:16: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n",
      "  app.launch_new_instance()\n",
      "/home/wx/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:19: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "/home/wx/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:20: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n",
      "/home/wx/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:23: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "/home/wx/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 112 / 1000 correct (11.20%)\n",
      "\n",
      "Iteration 100, loss = 2.3014\n",
      "Checking accuracy on validation set\n",
      "Got 122 / 1000 correct (12.20%)\n",
      "\n",
      "Iteration 200, loss = 2.1879\n",
      "Checking accuracy on validation set\n",
      "Got 160 / 1000 correct (16.00%)\n",
      "\n",
      "Iteration 300, loss = 2.2372\n",
      "Checking accuracy on validation set\n",
      "Got 170 / 1000 correct (17.00%)\n",
      "\n",
      "Iteration 400, loss = 2.1670\n",
      "Checking accuracy on validation set\n",
      "Got 255 / 1000 correct (25.50%)\n",
      "\n",
      "Iteration 500, loss = 2.0966\n",
      "Checking accuracy on validation set\n",
      "Got 270 / 1000 correct (27.00%)\n",
      "\n",
      "Iteration 600, loss = 2.1785\n",
      "Checking accuracy on validation set\n",
      "Got 317 / 1000 correct (31.70%)\n",
      "\n",
      "Iteration 700, loss = 1.8037\n",
      "Checking accuracy on validation set\n",
      "Got 337 / 1000 correct (33.70%)\n",
      "\n",
      "Iteration 0, loss = 1.8361\n",
      "Checking accuracy on validation set\n",
      "Got 333 / 1000 correct (33.30%)\n",
      "\n",
      "Iteration 100, loss = 1.5695\n",
      "Checking accuracy on validation set\n",
      "Got 334 / 1000 correct (33.40%)\n",
      "\n",
      "Iteration 200, loss = 1.6124\n",
      "Checking accuracy on validation set\n",
      "Got 349 / 1000 correct (34.90%)\n",
      "\n",
      "Iteration 300, loss = 1.7632\n",
      "Checking accuracy on validation set\n",
      "Got 418 / 1000 correct (41.80%)\n",
      "\n",
      "Iteration 400, loss = 1.7231\n",
      "Checking accuracy on validation set\n",
      "Got 396 / 1000 correct (39.60%)\n",
      "\n",
      "Iteration 500, loss = 1.4954\n",
      "Checking accuracy on validation set\n",
      "Got 429 / 1000 correct (42.90%)\n",
      "\n",
      "Iteration 600, loss = 1.4602\n",
      "Checking accuracy on validation set\n",
      "Got 456 / 1000 correct (45.60%)\n",
      "\n",
      "Iteration 700, loss = 1.3170\n",
      "Checking accuracy on validation set\n",
      "Got 459 / 1000 correct (45.90%)\n",
      "\n",
      "Iteration 0, loss = 1.4507\n",
      "Checking accuracy on validation set\n",
      "Got 453 / 1000 correct (45.30%)\n",
      "\n",
      "Iteration 100, loss = 1.2104\n",
      "Checking accuracy on validation set\n",
      "Got 460 / 1000 correct (46.00%)\n",
      "\n",
      "Iteration 200, loss = 1.2349\n",
      "Checking accuracy on validation set\n",
      "Got 460 / 1000 correct (46.00%)\n",
      "\n",
      "Iteration 300, loss = 1.4865\n",
      "Checking accuracy on validation set\n",
      "Got 459 / 1000 correct (45.90%)\n",
      "\n",
      "Iteration 400, loss = 1.5389\n",
      "Checking accuracy on validation set\n",
      "Got 463 / 1000 correct (46.30%)\n",
      "\n",
      "Iteration 500, loss = 1.3664\n",
      "Checking accuracy on validation set\n",
      "Got 509 / 1000 correct (50.90%)\n",
      "\n",
      "Iteration 600, loss = 1.4877\n",
      "Checking accuracy on validation set\n",
      "Got 500 / 1000 correct (50.00%)\n",
      "\n",
      "Iteration 700, loss = 1.2519\n",
      "Checking accuracy on validation set\n",
      "Got 514 / 1000 correct (51.40%)\n",
      "\n",
      "Iteration 0, loss = 1.2600\n",
      "Checking accuracy on validation set\n",
      "Got 547 / 1000 correct (54.70%)\n",
      "\n",
      "Iteration 100, loss = 1.2509\n",
      "Checking accuracy on validation set\n",
      "Got 551 / 1000 correct (55.10%)\n",
      "\n",
      "Iteration 200, loss = 1.4569\n",
      "Checking accuracy on validation set\n",
      "Got 516 / 1000 correct (51.60%)\n",
      "\n",
      "Iteration 300, loss = 1.2814\n",
      "Checking accuracy on validation set\n",
      "Got 581 / 1000 correct (58.10%)\n",
      "\n",
      "Iteration 400, loss = 1.1212\n",
      "Checking accuracy on validation set\n",
      "Got 557 / 1000 correct (55.70%)\n",
      "\n",
      "Iteration 500, loss = 1.2502\n",
      "Checking accuracy on validation set\n",
      "Got 565 / 1000 correct (56.50%)\n",
      "\n",
      "Iteration 600, loss = 1.2571\n",
      "Checking accuracy on validation set\n",
      "Got 511 / 1000 correct (51.10%)\n",
      "\n",
      "Iteration 700, loss = 1.1501\n",
      "Checking accuracy on validation set\n",
      "Got 595 / 1000 correct (59.50%)\n",
      "\n",
      "Iteration 0, loss = 1.2849\n",
      "Checking accuracy on validation set\n",
      "Got 583 / 1000 correct (58.30%)\n",
      "\n",
      "Iteration 100, loss = 1.1970\n",
      "Checking accuracy on validation set\n",
      "Got 599 / 1000 correct (59.90%)\n",
      "\n",
      "Iteration 200, loss = 0.9705\n",
      "Checking accuracy on validation set\n",
      "Got 612 / 1000 correct (61.20%)\n",
      "\n",
      "Iteration 300, loss = 1.0376\n",
      "Checking accuracy on validation set\n",
      "Got 604 / 1000 correct (60.40%)\n",
      "\n",
      "Iteration 400, loss = 1.2563\n",
      "Checking accuracy on validation set\n",
      "Got 615 / 1000 correct (61.50%)\n",
      "\n",
      "Iteration 500, loss = 1.0628\n",
      "Checking accuracy on validation set\n",
      "Got 638 / 1000 correct (63.80%)\n",
      "\n",
      "Iteration 600, loss = 0.9556\n",
      "Checking accuracy on validation set\n",
      "Got 627 / 1000 correct (62.70%)\n",
      "\n",
      "Iteration 700, loss = 0.8705\n",
      "Checking accuracy on validation set\n",
      "Got 642 / 1000 correct (64.20%)\n",
      "\n",
      "Iteration 0, loss = 0.9334\n",
      "Checking accuracy on validation set\n",
      "Got 616 / 1000 correct (61.60%)\n",
      "\n",
      "Iteration 100, loss = 1.0745\n",
      "Checking accuracy on validation set\n",
      "Got 636 / 1000 correct (63.60%)\n",
      "\n",
      "Iteration 200, loss = 1.0586\n",
      "Checking accuracy on validation set\n",
      "Got 665 / 1000 correct (66.50%)\n",
      "\n",
      "Iteration 300, loss = 0.9509\n",
      "Checking accuracy on validation set\n",
      "Got 657 / 1000 correct (65.70%)\n",
      "\n",
      "Iteration 400, loss = 0.8225\n",
      "Checking accuracy on validation set\n",
      "Got 671 / 1000 correct (67.10%)\n",
      "\n",
      "Iteration 500, loss = 0.8376\n",
      "Checking accuracy on validation set\n",
      "Got 675 / 1000 correct (67.50%)\n",
      "\n",
      "Iteration 600, loss = 0.9792\n",
      "Checking accuracy on validation set\n",
      "Got 659 / 1000 correct (65.90%)\n",
      "\n",
      "Iteration 700, loss = 0.9495\n",
      "Checking accuracy on validation set\n",
      "Got 688 / 1000 correct (68.80%)\n",
      "\n",
      "Iteration 0, loss = 0.8902\n",
      "Checking accuracy on validation set\n",
      "Got 661 / 1000 correct (66.10%)\n",
      "\n",
      "Iteration 100, loss = 0.8272\n",
      "Checking accuracy on validation set\n",
      "Got 659 / 1000 correct (65.90%)\n",
      "\n",
      "Iteration 200, loss = 0.8230\n",
      "Checking accuracy on validation set\n",
      "Got 666 / 1000 correct (66.60%)\n",
      "\n",
      "Iteration 300, loss = 0.7368\n",
      "Checking accuracy on validation set\n",
      "Got 697 / 1000 correct (69.70%)\n",
      "\n",
      "Iteration 400, loss = 0.8972\n",
      "Checking accuracy on validation set\n",
      "Got 693 / 1000 correct (69.30%)\n",
      "\n",
      "Iteration 500, loss = 0.6231\n",
      "Checking accuracy on validation set\n",
      "Got 716 / 1000 correct (71.60%)\n",
      "\n",
      "Iteration 600, loss = 0.6581\n",
      "Checking accuracy on validation set\n",
      "Got 708 / 1000 correct (70.80%)\n",
      "\n",
      "Iteration 700, loss = 0.8184\n",
      "Checking accuracy on validation set\n",
      "Got 701 / 1000 correct (70.10%)\n",
      "\n",
      "Iteration 0, loss = 0.7415\n",
      "Checking accuracy on validation set\n",
      "Got 697 / 1000 correct (69.70%)\n",
      "\n",
      "Iteration 100, loss = 0.7709\n",
      "Checking accuracy on validation set\n",
      "Got 691 / 1000 correct (69.10%)\n",
      "\n",
      "Iteration 200, loss = 0.6601\n",
      "Checking accuracy on validation set\n",
      "Got 710 / 1000 correct (71.00%)\n",
      "\n",
      "Iteration 300, loss = 0.6893\n",
      "Checking accuracy on validation set\n",
      "Got 701 / 1000 correct (70.10%)\n",
      "\n",
      "Iteration 400, loss = 0.8733\n",
      "Checking accuracy on validation set\n",
      "Got 705 / 1000 correct (70.50%)\n",
      "\n",
      "Iteration 500, loss = 0.7674\n",
      "Checking accuracy on validation set\n",
      "Got 705 / 1000 correct (70.50%)\n",
      "\n",
      "Iteration 600, loss = 0.9127\n",
      "Checking accuracy on validation set\n",
      "Got 729 / 1000 correct (72.90%)\n",
      "\n",
      "Iteration 700, loss = 0.9315\n",
      "Checking accuracy on validation set\n",
      "Got 731 / 1000 correct (73.10%)\n",
      "\n",
      "Iteration 0, loss = 0.6505\n",
      "Checking accuracy on validation set\n",
      "Got 708 / 1000 correct (70.80%)\n",
      "\n",
      "Iteration 100, loss = 0.7865\n",
      "Checking accuracy on validation set\n",
      "Got 684 / 1000 correct (68.40%)\n",
      "\n",
      "Iteration 200, loss = 0.7177\n",
      "Checking accuracy on validation set\n",
      "Got 720 / 1000 correct (72.00%)\n",
      "\n",
      "Iteration 300, loss = 0.5866\n",
      "Checking accuracy on validation set\n",
      "Got 735 / 1000 correct (73.50%)\n",
      "\n",
      "Iteration 400, loss = 0.5819\n",
      "Checking accuracy on validation set\n",
      "Got 732 / 1000 correct (73.20%)\n",
      "\n",
      "Iteration 500, loss = 0.9273\n",
      "Checking accuracy on validation set\n",
      "Got 741 / 1000 correct (74.10%)\n",
      "\n",
      "Iteration 600, loss = 0.9313\n",
      "Checking accuracy on validation set\n",
      "Got 699 / 1000 correct (69.90%)\n",
      "\n",
      "Iteration 700, loss = 0.7114\n",
      "Checking accuracy on validation set\n",
      "Got 715 / 1000 correct (71.50%)\n",
      "\n",
      "Iteration 0, loss = 0.6324\n",
      "Checking accuracy on validation set\n",
      "Got 742 / 1000 correct (74.20%)\n",
      "\n",
      "Iteration 100, loss = 0.6438\n",
      "Checking accuracy on validation set\n",
      "Got 746 / 1000 correct (74.60%)\n",
      "\n",
      "Iteration 200, loss = 0.4744\n",
      "Checking accuracy on validation set\n",
      "Got 737 / 1000 correct (73.70%)\n",
      "\n",
      "Iteration 300, loss = 0.6689\n",
      "Checking accuracy on validation set\n",
      "Got 734 / 1000 correct (73.40%)\n",
      "\n",
      "Iteration 400, loss = 0.6531\n",
      "Checking accuracy on validation set\n",
      "Got 727 / 1000 correct (72.70%)\n",
      "\n",
      "Iteration 500, loss = 0.5311\n",
      "Checking accuracy on validation set\n",
      "Got 757 / 1000 correct (75.70%)\n",
      "\n",
      "Iteration 600, loss = 0.8200\n",
      "Checking accuracy on validation set\n",
      "Got 747 / 1000 correct (74.70%)\n",
      "\n",
      "Iteration 700, loss = 0.8715\n",
      "Checking accuracy on validation set\n",
      "Got 745 / 1000 correct (74.50%)\n",
      "\n",
      "Iteration 0, loss = 0.8394\n",
      "Checking accuracy on validation set\n",
      "Got 748 / 1000 correct (74.80%)\n",
      "\n",
      "Iteration 100, loss = 0.7354\n",
      "Checking accuracy on validation set\n",
      "Got 724 / 1000 correct (72.40%)\n",
      "\n",
      "Iteration 200, loss = 0.4942\n",
      "Checking accuracy on validation set\n",
      "Got 751 / 1000 correct (75.10%)\n",
      "\n",
      "Iteration 300, loss = 0.4974\n",
      "Checking accuracy on validation set\n",
      "Got 741 / 1000 correct (74.10%)\n",
      "\n",
      "Iteration 400, loss = 0.5942\n",
      "Checking accuracy on validation set\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 754 / 1000 correct (75.40%)\n",
      "\n",
      "Iteration 500, loss = 0.7438\n",
      "Checking accuracy on validation set\n",
      "Got 724 / 1000 correct (72.40%)\n",
      "\n",
      "Iteration 600, loss = 0.7187\n",
      "Checking accuracy on validation set\n",
      "Got 759 / 1000 correct (75.90%)\n",
      "\n",
      "Iteration 700, loss = 0.8174\n",
      "Checking accuracy on validation set\n",
      "Got 767 / 1000 correct (76.70%)\n",
      "\n",
      "Iteration 0, loss = 0.4511\n",
      "Checking accuracy on validation set\n",
      "Got 744 / 1000 correct (74.40%)\n",
      "\n",
      "Iteration 100, loss = 0.6062\n",
      "Checking accuracy on validation set\n",
      "Got 761 / 1000 correct (76.10%)\n",
      "\n",
      "Iteration 200, loss = 0.8505\n",
      "Checking accuracy on validation set\n",
      "Got 734 / 1000 correct (73.40%)\n",
      "\n",
      "Iteration 300, loss = 0.5124\n",
      "Checking accuracy on validation set\n",
      "Got 748 / 1000 correct (74.80%)\n",
      "\n",
      "Iteration 400, loss = 0.6082\n",
      "Checking accuracy on validation set\n",
      "Got 764 / 1000 correct (76.40%)\n",
      "\n",
      "Iteration 500, loss = 0.4851\n",
      "Checking accuracy on validation set\n",
      "Got 755 / 1000 correct (75.50%)\n",
      "\n",
      "Iteration 600, loss = 0.6996\n",
      "Checking accuracy on validation set\n",
      "Got 774 / 1000 correct (77.40%)\n",
      "\n",
      "Iteration 700, loss = 0.6151\n",
      "Checking accuracy on validation set\n",
      "Got 778 / 1000 correct (77.80%)\n",
      "\n",
      "Iteration 0, loss = 0.7853\n",
      "Checking accuracy on validation set\n",
      "Got 774 / 1000 correct (77.40%)\n",
      "\n",
      "Iteration 100, loss = 0.4873\n",
      "Checking accuracy on validation set\n",
      "Got 754 / 1000 correct (75.40%)\n",
      "\n",
      "Iteration 200, loss = 0.6204\n",
      "Checking accuracy on validation set\n",
      "Got 778 / 1000 correct (77.80%)\n",
      "\n",
      "Iteration 300, loss = 0.6789\n",
      "Checking accuracy on validation set\n",
      "Got 785 / 1000 correct (78.50%)\n",
      "\n",
      "Iteration 400, loss = 0.5381\n",
      "Checking accuracy on validation set\n",
      "Got 788 / 1000 correct (78.80%)\n",
      "\n",
      "Iteration 500, loss = 0.6768\n",
      "Checking accuracy on validation set\n",
      "Got 777 / 1000 correct (77.70%)\n",
      "\n",
      "Iteration 600, loss = 0.5382\n",
      "Checking accuracy on validation set\n",
      "Got 706 / 1000 correct (70.60%)\n",
      "\n",
      "Iteration 700, loss = 0.7679\n",
      "Checking accuracy on validation set\n",
      "Got 764 / 1000 correct (76.40%)\n",
      "\n",
      "Iteration 0, loss = 0.5716\n",
      "Checking accuracy on validation set\n",
      "Got 760 / 1000 correct (76.00%)\n",
      "\n",
      "Iteration 100, loss = 0.4733\n",
      "Checking accuracy on validation set\n",
      "Got 775 / 1000 correct (77.50%)\n",
      "\n",
      "Iteration 200, loss = 0.4706\n",
      "Checking accuracy on validation set\n",
      "Got 787 / 1000 correct (78.70%)\n",
      "\n",
      "Iteration 300, loss = 0.3123\n",
      "Checking accuracy on validation set\n",
      "Got 777 / 1000 correct (77.70%)\n",
      "\n",
      "Iteration 400, loss = 0.3896\n",
      "Checking accuracy on validation set\n",
      "Got 806 / 1000 correct (80.60%)\n",
      "\n",
      "Iteration 500, loss = 0.5285\n",
      "Checking accuracy on validation set\n",
      "Got 746 / 1000 correct (74.60%)\n",
      "\n",
      "Iteration 600, loss = 0.5237\n",
      "Checking accuracy on validation set\n",
      "Got 789 / 1000 correct (78.90%)\n",
      "\n",
      "Iteration 700, loss = 0.3544\n",
      "Checking accuracy on validation set\n",
      "Got 784 / 1000 correct (78.40%)\n",
      "\n",
      "Iteration 0, loss = 0.3381\n",
      "Checking accuracy on validation set\n",
      "Got 767 / 1000 correct (76.70%)\n",
      "\n",
      "Iteration 100, loss = 0.4739\n",
      "Checking accuracy on validation set\n",
      "Got 784 / 1000 correct (78.40%)\n",
      "\n",
      "Iteration 200, loss = 0.3859\n",
      "Checking accuracy on validation set\n",
      "Got 794 / 1000 correct (79.40%)\n",
      "\n",
      "Iteration 300, loss = 0.3992\n",
      "Checking accuracy on validation set\n",
      "Got 791 / 1000 correct (79.10%)\n",
      "\n",
      "Iteration 400, loss = 0.5528\n",
      "Checking accuracy on validation set\n",
      "Got 787 / 1000 correct (78.70%)\n",
      "\n",
      "Iteration 500, loss = 0.4872\n",
      "Checking accuracy on validation set\n",
      "Got 777 / 1000 correct (77.70%)\n",
      "\n",
      "Iteration 600, loss = 0.5168\n",
      "Checking accuracy on validation set\n",
      "Got 779 / 1000 correct (77.90%)\n",
      "\n",
      "Iteration 700, loss = 0.4962\n",
      "Checking accuracy on validation set\n",
      "Got 795 / 1000 correct (79.50%)\n",
      "\n",
      "Iteration 0, loss = 0.8082\n",
      "Checking accuracy on validation set\n",
      "Got 780 / 1000 correct (78.00%)\n",
      "\n",
      "Iteration 100, loss = 0.5365\n",
      "Checking accuracy on validation set\n",
      "Got 802 / 1000 correct (80.20%)\n",
      "\n",
      "Iteration 200, loss = 0.5065\n",
      "Checking accuracy on validation set\n",
      "Got 770 / 1000 correct (77.00%)\n",
      "\n",
      "Iteration 300, loss = 0.3890\n",
      "Checking accuracy on validation set\n",
      "Got 796 / 1000 correct (79.60%)\n",
      "\n",
      "Iteration 400, loss = 0.4176\n",
      "Checking accuracy on validation set\n",
      "Got 788 / 1000 correct (78.80%)\n",
      "\n",
      "Iteration 500, loss = 0.4380\n",
      "Checking accuracy on validation set\n",
      "Got 796 / 1000 correct (79.60%)\n",
      "\n",
      "Iteration 600, loss = 0.5717\n",
      "Checking accuracy on validation set\n",
      "Got 800 / 1000 correct (80.00%)\n",
      "\n",
      "Iteration 700, loss = 0.5240\n",
      "Checking accuracy on validation set\n",
      "Got 804 / 1000 correct (80.40%)\n",
      "\n",
      "Iteration 0, loss = 0.3016\n",
      "Checking accuracy on validation set\n",
      "Got 776 / 1000 correct (77.60%)\n",
      "\n",
      "Iteration 100, loss = 0.4269\n",
      "Checking accuracy on validation set\n",
      "Got 779 / 1000 correct (77.90%)\n",
      "\n",
      "Iteration 200, loss = 0.3449\n",
      "Checking accuracy on validation set\n",
      "Got 774 / 1000 correct (77.40%)\n",
      "\n",
      "Iteration 300, loss = 0.4301\n",
      "Checking accuracy on validation set\n",
      "Got 812 / 1000 correct (81.20%)\n",
      "\n",
      "Iteration 400, loss = 0.6702\n",
      "Checking accuracy on validation set\n",
      "Got 794 / 1000 correct (79.40%)\n",
      "\n",
      "Iteration 500, loss = 0.7547\n",
      "Checking accuracy on validation set\n",
      "Got 769 / 1000 correct (76.90%)\n",
      "\n",
      "Iteration 600, loss = 0.3917\n",
      "Checking accuracy on validation set\n",
      "Got 791 / 1000 correct (79.10%)\n",
      "\n",
      "Iteration 700, loss = 0.4354\n",
      "Checking accuracy on validation set\n",
      "Got 794 / 1000 correct (79.40%)\n",
      "\n",
      "Iteration 0, loss = 0.2266\n",
      "Checking accuracy on validation set\n",
      "Got 799 / 1000 correct (79.90%)\n",
      "\n",
      "Iteration 100, loss = 0.4595\n",
      "Checking accuracy on validation set\n",
      "Got 780 / 1000 correct (78.00%)\n",
      "\n",
      "Iteration 200, loss = 0.4312\n",
      "Checking accuracy on validation set\n",
      "Got 809 / 1000 correct (80.90%)\n",
      "\n",
      "Iteration 300, loss = 0.3600\n",
      "Checking accuracy on validation set\n",
      "Got 800 / 1000 correct (80.00%)\n",
      "\n",
      "Iteration 400, loss = 0.3750\n",
      "Checking accuracy on validation set\n",
      "Got 807 / 1000 correct (80.70%)\n",
      "\n",
      "Iteration 500, loss = 0.6063\n",
      "Checking accuracy on validation set\n",
      "Got 797 / 1000 correct (79.70%)\n",
      "\n",
      "Iteration 600, loss = 0.3716\n",
      "Checking accuracy on validation set\n",
      "Got 784 / 1000 correct (78.40%)\n",
      "\n",
      "Iteration 700, loss = 0.5062\n",
      "Checking accuracy on validation set\n",
      "Got 778 / 1000 correct (77.80%)\n",
      "\n",
      "Iteration 0, loss = 0.3157\n",
      "Checking accuracy on validation set\n",
      "Got 803 / 1000 correct (80.30%)\n",
      "\n",
      "Iteration 100, loss = 0.4346\n",
      "Checking accuracy on validation set\n",
      "Got 806 / 1000 correct (80.60%)\n",
      "\n",
      "Iteration 200, loss = 0.3581\n",
      "Checking accuracy on validation set\n",
      "Got 796 / 1000 correct (79.60%)\n",
      "\n",
      "Iteration 300, loss = 0.4610\n",
      "Checking accuracy on validation set\n",
      "Got 802 / 1000 correct (80.20%)\n",
      "\n",
      "Iteration 400, loss = 0.3779\n",
      "Checking accuracy on validation set\n",
      "Got 821 / 1000 correct (82.10%)\n",
      "\n",
      "Iteration 500, loss = 0.4192\n",
      "Checking accuracy on validation set\n",
      "Got 807 / 1000 correct (80.70%)\n",
      "\n",
      "Iteration 600, loss = 0.4690\n",
      "Checking accuracy on validation set\n",
      "Got 799 / 1000 correct (79.90%)\n",
      "\n",
      "Iteration 700, loss = 0.3347\n",
      "Checking accuracy on validation set\n",
      "Got 804 / 1000 correct (80.40%)\n",
      "\n",
      "Iteration 0, loss = 0.5127\n",
      "Checking accuracy on validation set\n",
      "Got 792 / 1000 correct (79.20%)\n",
      "\n",
      "Iteration 100, loss = 0.2672\n",
      "Checking accuracy on validation set\n",
      "Got 797 / 1000 correct (79.70%)\n",
      "\n",
      "Iteration 200, loss = 0.3515\n",
      "Checking accuracy on validation set\n",
      "Got 790 / 1000 correct (79.00%)\n",
      "\n",
      "Iteration 300, loss = 0.2781\n",
      "Checking accuracy on validation set\n",
      "Got 795 / 1000 correct (79.50%)\n",
      "\n",
      "Iteration 400, loss = 0.3188\n",
      "Checking accuracy on validation set\n",
      "Got 802 / 1000 correct (80.20%)\n",
      "\n",
      "Iteration 500, loss = 0.3622\n",
      "Checking accuracy on validation set\n",
      "Got 800 / 1000 correct (80.00%)\n",
      "\n",
      "Iteration 600, loss = 0.4176\n",
      "Checking accuracy on validation set\n",
      "Got 810 / 1000 correct (81.00%)\n",
      "\n",
      "Iteration 700, loss = 0.4618\n",
      "Checking accuracy on validation set\n",
      "Got 797 / 1000 correct (79.70%)\n",
      "\n",
      "Checking accuracy on test set\n",
      "Got 7880 / 10000 correct (78.80%)\n"
     ]
    }
   ],
   "source": [
    "model_ALLC = None\n",
    "optimizer = None\n",
    "from torch.nn import init\n",
    "class ALLC(nn.Module):\n",
    "    def __init__(self,input_size,n_classes=10,**kwargs):\n",
    "        super(ALLC,self).__init__() \n",
    "        self.conv1 = nn.Conv2d(input_size,96,3,padding=1)\n",
    "        init.xavier_uniform(self.conv1.weight, gain=np.sqrt(2.0))\n",
    "        init.constant(self.conv1.bias, 0.1) \n",
    "        self.conv2 = nn.Conv2d(96,96,3,padding=1)\n",
    "        init.xavier_uniform(self.conv2.weight, gain=np.sqrt(2.0))\n",
    "        init.constant(self.conv2.bias, 0.1)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(96,96,3,padding=1,stride=2)\n",
    "        init.xavier_uniform(self.conv3.weight, gain=np.sqrt(2.0))\n",
    "        init.constant(self.conv3.bias, 0.1)\n",
    "        \n",
    "        self.conv4 = nn.Conv2d(96,192,3,padding=1)\n",
    "        init.xavier_uniform(self.conv4.weight, gain=np.sqrt(2.0))\n",
    "        init.constant(self.conv4.bias, 0.1)\n",
    "        \n",
    "        self.conv5 = nn.Conv2d(192,192,3,padding=1)  \n",
    "        self.conv6 = nn.Conv2d(192,192,3,padding=1,stride=2)\n",
    "        self.conv7 = nn.Conv2d(192,192,3,padding=1)\n",
    "        self.conv8 = nn.Conv2d(192,192,1,padding=0)\n",
    "        self.class_conv = nn.Conv2d(192,n_classes,1,padding=0)\n",
    "    def forward(self,x): \n",
    "        #add drop\n",
    "        x_drop = F.dropout(x,0.2)\n",
    "        conv1_out = F.relu(self.conv1(x_drop))\n",
    "        conv2_out = F.relu(self.conv2(conv1_out))\n",
    "        conv3_out = F.relu(self.conv3(conv2_out))\n",
    "        \n",
    "        conv3_out = F.dropout(conv3_out,0.5)\n",
    "        \n",
    "        conv4_out = F.relu(self.conv4(conv3_out)) \n",
    "        conv5_out = F.relu(self.conv5(conv4_out))\n",
    "        conv6_out = F.relu(self.conv6(conv5_out))\n",
    "        \n",
    "        conv6_out = F.dropout(conv6_out,0.5)\n",
    "        \n",
    "        conv7_out = F.relu(self.conv7(conv6_out)) \n",
    "        conv8_out = F.relu(self.conv8(conv7_out))\n",
    "        class_out = F.relu(self.class_conv(conv8_out))\n",
    "        \n",
    "        pool_out = F.avg_pool2d(class_out,kernel_size=6)\n",
    "        pool_out.squeeze_(-1)\n",
    "        pool_out.squeeze_(-1)\n",
    "        \n",
    "        return pool_out\n",
    "\n",
    "model_ALLC = ALLC(3)\n",
    "       \n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model_ALLC.parameters(), lr=0.01,\n",
    "                     momentum=0.9,weight_decay=0.001,nesterov=True)\n",
    "\n",
    "train(model_ALLC, optimizer, epochs=20) \n",
    "check_accuracy(loader_test, model_ALLC.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "torch.save(model_ALLC.state_dict(),'model_ALLC.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
